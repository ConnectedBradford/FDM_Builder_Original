{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dddb629",
   "metadata": {},
   "source": [
    "## Tutorial Prerequisites:\n",
    "\n",
    "It's recommended you have an empty dataset in GCP to play around with the FDMBuilder tools - so either create one now in preparation, or ask someone with the relevant priviledges to make one for you if you can't.\n",
    "\n",
    "## Quick Jupyter notebooks primer\n",
    "\n",
    "A jupyter notebook allows you to write markdown and execute python/R script in one document. \n",
    "\n",
    "This text has been written in a markdown cell (double click right here and you'll be able to edit the markdown). Running a markdown cell renders it (so displaying the markdown in it's non-scripted format).\n",
    "\n",
    "Immediately below this is the first code cell - it contains script that imports all of the required python libraries to run the FDMBuilder. Any output from a code cell will be displayed immediately below the cell.\n",
    "\n",
    "Be sure to write text and documentation in a markdown cell, and script in a code cell - otherwise you'll get some pretty colourful errors!\n",
    "\n",
    "There are a bunch of controls to manage each cell in the notebook: the UI has buttons above that can run a code cell, change a code cell to a markdown cell or visa-versa, stop execution of a code cell, execute every cell in the notebook, and so on... Hover over each of the buttons above to see what they do. You can also perform all cell-related activities by selecting the `Cell` menu in the toolbar and choosing the relevant option.\n",
    "\n",
    "However, hotkeys are usually the easiest way to quickly run code cells (and render markdown). Simply select a code cell and:\n",
    "\n",
    "* press `ctrl+enter` to run the cell \n",
    "* press `shift+enter` to run the cell and move focus to the cell below\n",
    "* press `ctrl+shift+enter` to run the cell and create a new code cell below\n",
    "\n",
    "That should be enough to get started - plenty of other online guides exist if you want to get better acquainted with the jupyter notebook environment.\n",
    "\n",
    "Get started by running the below code cell, which imports all the required python libraries for the FDMBuilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff11e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FDMBuilder.FDMTable import *\n",
    "from FDMBuilder.FDMDataset import *\n",
    "from FDMBuilder.testing_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc0cf-0d42-4107-bdaa-b6ce4076c2be",
   "metadata": {},
   "source": [
    "## FDM Builder - The basics\n",
    "\n",
    "Note: This guide assumes you're familiar with the term FDM and associated concepts.\n",
    "\n",
    "The FDMBuilder library has been designed with the hope that a non-python user shouldn't (hopefully) have too much difficulty using the FDM tools to build a dataset from scratch. The workflow is split into two major steps:\n",
    "\n",
    "1. Prepare the source tables\n",
    "2. Build the FDM\n",
    "\n",
    "Each step comes with it's own tool or helper that walks through the process of preparing and bulding an FDM dataset. Source tables are \"built\" or prepared for the FDM process with the `FDMTable` tool - this is a python \"class\" that contains all the bits and pieces needed to clean and prep a table for FDMing. Once all the source tables are ready, the FDM dataset itself is \"built\" using the `FDMDataset` tool - another python class responsible for drawing all the source tables together and building the standard FDM tables (person and observation_period).\n",
    "\n",
    "We'll begin with the basics of using the FDMTable and FDMDataset tools to buld an FDM dataset. Once we're more comfortable with the python workflow, we can then move onto the more \"advanced\" functions that can streamline many of the more common cleaning/manipulation activities that pop up during the FDM process.\n",
    "\n",
    "## FDMTable\n",
    "\n",
    "To begin the FDM process, we need to prep each source table. This process ensures that:\n",
    "\n",
    "1. The source table is copied to the FDM dataset location\n",
    "2. person_ids are added to each entry\n",
    "3. An event_start_date is added to each entry in a cleaned `DATETIME` format\n",
    "4. If needed an event_end_date is added to each entry in a cleaned `DATETIME` format\n",
    "\n",
    "To do this using the python FDMBuilder, you first need to define an individual FDMTable object for each of the source tables in your FDM dataset. The below is an example of the python script you would use to initialise an `FDMTable` object:\n",
    "\n",
    "```\n",
    "test_table_1 = FDMTable(\n",
    "    source_table_id=\"SOURCE_TABLE.LOCATION_GOES_HERE\",\n",
    "    dataset_id=\"FDM_DATASET_ID_GOES_HERE\"\n",
    ")\n",
    "```\n",
    "\n",
    "The above code cell creates a new FDMTable object and stores it as a python variable `test_table_1` - the arguments when creating or initialising an FDMTable are:\n",
    "\n",
    "* `source_table_id`: the id of the source table (hopefully that wasn't a surprise!). This can be in \"project.dataset_id.table_id\" form or just \"dataset_id.table_id\" form\n",
    "* `dataset_id`: the id of the dataset in which you'll be copying/building your FDM dataset \n",
    "\n",
    "    Note: This is hopeuflly obvious, but you'll need to change \"SOURCE_TABLE.LOCATION_GOES_HERE\" and \"FDM_DATASET_ID_GOES_HERE\" for the actual GCP locations of the source table and the FDM dataset.\n",
    "    \n",
    "Let's have a go at initialising a dataset ourselves. We'll be using a pre-prepared source dataset that can be found in `CY_FDM_BUILDER_TESTS` and we'll start with `test_table_1`. Take a quick look in the BigQuery SQL workspace to check you have acess to the test dataset and that you can find `test_table_1` in there (if not give me - Sam - a shout). Next, you'll need to create your own dataset to store your test FDM tables - do that now. Then, replace `YOUR_FDM_DATASET_ID_GOES_HERE` in the below code cell with the actual id of the new dataset you just created, and then run the cell (shift+enter, or the play button above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f7a5c2-7574-4007-af36-f41efdfad28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table_1 = FDMTable(\n",
    "    source_table_id=\"CY_FDM_BUILDER_TESTS.test_table_1\",\n",
    "    dataset_id=\"CY_MYSPACE_SR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ab429-e36f-403d-9d83-77c2f7a795d3",
   "metadata": {},
   "source": [
    "Don't worry if that was a little anti-climactic - initialising an FDMTable doesn't actually do anything in GCP. For that you need to call one of the FDMTable's \"methods\". Methods are functions attached to a specific class, that update/manipulate/otherwise mess about with the related class. So, the FDMTable class has methods that do things like add columns to the associated table, delete columns, rename columns etc. etc.\n",
    "\n",
    "To start, we'll look at the most of important of these methods `build` - fortunately it's also the easiest to get to grips with. Methods are called by specifying the class object, followed by a `.` and then the name of the method. So we call the `build` method on the above FDMTable we just defined by running:\n",
    "\n",
    "```\n",
    "test_table_1.build()\n",
    "```\n",
    "\n",
    "The `build` method is designed to walk the user through the process of preparing an FDM table, stopping each time user input is required. Each time the script stops, it will give a short explanation why and will ask for input with a bit of guidance on the input required.\n",
    "\n",
    "Give it a try! Run the below cell to build your first FDM table - simply read what the build script says and enter the required input when asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b9ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ##### BUILDING FDM TABLE COMPONENTS FOR test_table_1 #####\n",
      "________________________________________________________________________________\n",
      "\n",
      "1. Copying test_table_1 to CY_MYSPACE_SR:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    A copy of test_table_1 already exists in CY_MYSPACE_SR. \n",
      "    You can continue with the existing test_table_1 table in CY_MYSPACE_SR\n",
      "    or make a fresh copy from the source dataset.\"   \n",
      "    \n",
      "    Continue with existing copy?\n",
      "    > Type y or n:  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Table test_table_1 copied to CY_MYSPACE_SR!\n",
      "\n",
      "2. Adding person_id column:\n",
      "    test_table_1 already contains person_id column\n",
      "\n",
      "3. Adding event_start_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event start date is required to build the observation_period table. This \n",
      "    information should be contained within one or more columns of your table. \n",
      "    If unsure a quick look at the table data in BigQuery should clarify.\n",
      "    \n",
      "    To start, is the event start data found in one column that can be easily \n",
      "    parsed with a day, month and year?\n",
      "    > Type y or n  start_date\n",
      "    Your response didn't match y or n.\n",
      "    > Try again:  y\n",
      "\n",
      "    Which column contains the event start date?\n",
      "    > Type the name (case sensitive):  start_date\n",
      "\n",
      "    What format does the date appear in YMD/YDM/DMY/MDY?\n",
      "    > Type one:  YMD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    event_start_date column added\n",
      "\n",
      "4. Adding event_end_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event end date may or may not be relevant to this source data. For example, \n",
      "    hospital visits or academic school years have an end date as well as a start \n",
      "    date.\n",
      "\n",
      "    If you're unsure weather or not the source data should include an event end \n",
      "    date, seek help from the CYP data team.\"\n",
      "\n",
      "    Does this data have an event end date?\"\n",
      "    > Type y or n:  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "\n",
      "\t ##### BUILD PROCESS FOR test_table_1 COMPLETE! #####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_table_1.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985104e-269c-47ec-a3d7-9c15042ddb19",
   "metadata": {},
   "source": [
    "Hopefuly that went without a hitch! If not give me a shout... \n",
    "\n",
    "If you quickly take a look over at GCP and give your tab a quick refresh, you should notice that your test dataset now contains a copy of `test_table_1` and the table has a shiny new `event_start_date` column. You'll also notice the parser has taken a string with text and digits and has converted it into a SQL datetime - this should hopefully save a lot of manual faff in the long run!\n",
    "\n",
    "This was a pretty simple example that didn't ask much of the FDMBuilder - the second example throws a couple more curveballs into the mix, but hopefully the build script should still guide you through. When you're ready, run the below code cell:\n",
    "\n",
    "(as before, be sure to replace `YOUR_FDM_DATASET_ID_GOES_HERE` with your own test dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a751804c-d382-4368-8586-11e2fbc483ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "yhcr-prd-phm-bia-core.CY_FDM_BUILDER_TESTS.blyasdkf doesn't exist - double check spelling and GCP then try again",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27606/3138347206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test_table_2 = FDMTable(\n\u001b[1;32m      2\u001b[0m     \u001b[0msource_table_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CY_FDM_BUILDER_TESTS.blyasdkf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"caklsgjd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cy_fdm_builder/FDMBuilder/FDMTable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_table_id, dataset_id)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_table_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_table_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{source_table_id} doesn't exist - double check spelling and GCP then try again\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_dataset_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{dataset_id} doesn't exist - double check spelling and GCP then try again\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: yhcr-prd-phm-bia-core.CY_FDM_BUILDER_TESTS.blyasdkf doesn't exist - double check spelling and GCP then try again"
     ]
    }
   ],
   "source": [
    "test_table_2 = FDMTable(\n",
    "    source_table_id=\"CY_FDM_BUILDER_TESTS.blyasdkf\",\n",
    "    dataset_id=\"caklsgjd\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02814439-d375-4580-9ba6-9d501e82982b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dddb629",
   "metadata": {},
   "source": [
    "## Quick Jupyter notebooks primer\n",
    "\n",
    "A jupyter notebook allows you to write markdown and execute python/R script in one document. \n",
    "\n",
    "This text has been written in a markdown cell (double click right here and you'll be able to edit the markdown). Running a markdown cell renders it (so displaying the markdown in it's non-scripted format).\n",
    "\n",
    "Immediately below this is the first code cell - it contains script that imports all of the required python libraries to run the FDMBuilder. Any output from a code cell will be displayed immediately below the cell.\n",
    "\n",
    "Be sure to write text and documentation in a markdown cell, and script in a code cell - otherwise you'll get some pretty colourful errors!\n",
    "\n",
    "There are a bunch of controls to manage each cell in the notebook: the UI has buttons above that can run a code cell, change a code cell to a markdown cell or visa-versa, stop execution of a code cell, execute every cell in the notebook, and so on... Hover over each of the buttons above to see what they do. You can also perform all cell-related activities by selecting the `Cell` menu in the toolbar and choosing the relevant option.\n",
    "\n",
    "However, hotkeys are usually the easiest way to quickly run code cells (and render markdown). Simply select a code cell and:\n",
    "\n",
    "* press `ctrl+enter` to run the cell \n",
    "* press `shift+enter` to run the cell and move focus to the cell below\n",
    "* press `ctrl+shift+enter` to run the cell and create a new code cell below\n",
    "\n",
    "That should be enough to get started - plenty of other online guides exist if you want to get better acquainted with the jupyter notebook environment.\n",
    "\n",
    "Get started by running the below code cell, which imports all the required python libraries for the FDMBuilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff11e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FDMBuilder.FDMTable import *\n",
    "from FDMBuilder.FDMDataset import *\n",
    "from FDMBuilder.testing_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36098117-4505-462f-b960-b1c2b5b87342",
   "metadata": {},
   "source": [
    "## Tutorial Prerequisites:\n",
    "\n",
    "You'll need to have an empty dataset in GCP to play around with the FDMBuilder tools - so either create one now in preparation, or ask someone with the relevant priviledges to make one for you if you can't.\n",
    "\n",
    "Once you have a dataset, replace the `YOUR_DATASET_HERE` below with your dataset's id (be sure to keep the quotes or python will get upset with you):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca4d33f-b6f3-4634-a9d7-9d18f9934032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = \"CY_SAM_TEST\"\n",
    "if check_dataset_exists(DATASET_ID):\n",
    "    print(\"Good to go!\")\n",
    "else:\n",
    "    print(\"#\" * 33 + \" PROBLEM!! \" + 33 * \"#\" + \"\\n\")\n",
    "    print(\"Something doesn't look right. Check you spelled everything correctly,\\n\" \n",
    "          \"your dataset has been created in GCP, and you have the right permisssions\\n\")\n",
    "    print(\"#\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc0cf-0d42-4107-bdaa-b6ce4076c2be",
   "metadata": {},
   "source": [
    "As you may have figured out, the above code stores the name of your new dataset in a variable called `DATASET_ID`, and does a quick check to make sure the dataset exists - this just makes the following examples a little easier to run without any silly errors occurring. Hopefully you should see a message saying `Good to go!` in the cell output above.\n",
    "\n",
    "We'll also be using a couple of pre-prepared source datasets that can be found in `CY_FDM_BUILDER_TESTS`. Take a quick look in the BigQuery SQL workspace to check you've been given access to the test dataset and that you can see the two test tables, `test_table_1` & `test_table_2`, in there (if not give me - Sam - a shout). \n",
    "\n",
    "## FDM Builder - The basics\n",
    "\n",
    "Note: This guide assumes you're familiar with the term FDM and associated concepts.\n",
    "\n",
    "The FDMBuilder library has been designed with the hope that a non-python user shouldn't (hopefully) have too much difficulty using the FDM tools to build a dataset from scratch. The workflow is split into two major steps:\n",
    "\n",
    "1. Prepare the source tables\n",
    "2. Build the FDM\n",
    "\n",
    "Each step comes with it's own tool or helper that walks through the process of preparing and bulding an FDM dataset. Source tables are \"built\" or prepared for the FDM process with the `FDMTable` tool - this is a python \"class\" that contains all the bits and pieces needed to clean and prep a table for FDMing. Once all the source tables are ready, the FDM dataset itself is \"built\" using the `FDMDataset` tool - another python class responsible for drawing all the source tables together and building the standard FDM tables (person and observation_period).\n",
    "\n",
    "We'll begin with the basics of using the FDMTable and FDMDataset tools to buld an FDM dataset. Once we're more comfortable with the python workflow, we can then move onto the more \"advanced\" functions that can streamline many of the more common cleaning/manipulation activities that pop up during the FDM process.\n",
    "\n",
    "## FDMTable\n",
    "\n",
    "To begin the FDM process, we need to prep each source table. This process ensures that:\n",
    "\n",
    "1. The source table is copied to the FDM dataset location\n",
    "2. person_ids are added to each entry\n",
    "3. An event_start_date is added to each entry in a cleaned `DATETIME` format\n",
    "4. If needed an event_end_date is added to each entry in a cleaned `DATETIME` format\n",
    "\n",
    "To do this using the python FDMBuilder, you first need to define an individual FDMTable object for each of the source tables in your FDM dataset. We can do just that by running the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4b5091-08fb-4e10-9442-0b578cada2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table_1 = FDMTable(\n",
    "    source_table_id=\"CY_FDM_BUILDER_TESTS.test_table_1\",\n",
    "    dataset_id=DATASET_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2575ca3-5424-46b4-884a-616498aa1205",
   "metadata": {},
   "source": [
    "The above code cell creates a new FDMTable object and stores it as a python variable `test_table_1` - the arguments when creating or initialising an FDMTable are:\n",
    "\n",
    "* `source_table_id`: the id of the source table (hopefully that wasn't a surprise!). This can be in \"project.dataset_id.table_id\" form or just \"dataset_id.table_id\" form\n",
    "* `dataset_id`: the id of the dataset in which you'll be copying/building your FDM dataset - in this tutorial all such the `dataset_id` parameter intputs will be replaced with the `DATASET_ID` variable we created at the beginning of the notebook\n",
    "\n",
    "Initialising the `FDMTable` class FDMTable doesn't actually do anything particularly substantive - it just creates and stores an object in python. To start working with the tool, you need to run or \"call\" one of the FDMTable's \"methods\". Methods are functions attached to a specific class, that update/manipulate/otherwise mess about with the related class object. So the FDMTable class has methods that manipulate the associated FDM table in GCP doing things like adding/deleting/renaming columns and so on.\n",
    "\n",
    "To start, we'll look at the most of important of these methods `build` - fortunately it's also the easiest to get to grips with. Methods are called by specifying the class object, followed by a `.` and then the name of the method. So we call the `build` method on the above FDMTable we just defined by running:\n",
    "\n",
    "```\n",
    "test_table_1.build()\n",
    "```\n",
    "\n",
    "The `build` method is designed to walk the user through the process of preparing an FDM table, stopping each time user input is required. Each time the script stops, it will give a short explanation why and will ask for input with a bit of guidance on the input required.\n",
    "\n",
    "Give it a try! Run the below cell to build your first FDM table - simply read what the build script says and enter the required input when asked:\n",
    "\n",
    "(Note: You'll need the soure table available in a separate SQL workspace, so you can preview the data in `test_table_1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72990447-f1b6-4cd7-a95d-41d5edac52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_dataset(DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b9ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ##### BUILDING FDM TABLE COMPONENTS FOR test_table_1 #####\n",
      "________________________________________________________________________________\n",
      "\n",
      "1. Copying test_table_1 to CY_SAM_TEST:\n",
      "\n",
      "    Table test_table_1 copied to CY_SAM_TEST!\n",
      "\n",
      "2. Adding person_id column:\n",
      "    test_table_1 already contains person_id column\n",
      "\n",
      "3. Adding fdm_start_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event start date is required to build the observation_period table. This \n",
      "    information should be contained within one or more columns of your table. \n",
      "    If unsure a quick look at the table data in BigQuery should clarify.\n",
      "    \n",
      "    To start, is the event start data found in one column that can be easily \n",
      "    parsed with a day, month and year?\n",
      "    > Type y or n  y\n",
      "\n",
      "    Which column contains the event start date?\n",
      "    > Type the name (case sensitive):  start_date\n",
      "\n",
      "    What format does the date appear in YMD/YDM/DMY/MDY?\n",
      "    > Type one:  YMD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fdm_start_date column added\n",
      "\n",
      "4. Adding fdm_end_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event end date may or may not be relevant to this source data. For example, \n",
      "    hospital visits or academic school years have an end date as well as a start \n",
      "    date.\n",
      "    If you're unsure weather or not the source data should include an event end \n",
      "    date, seek help from the CYP data team.\"\n",
      "    Does this data have an event end date?\"\n",
      "    > Type y or n:  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "\n",
      "\t ##### BUILD PROCESS FOR test_table_1 COMPLETE! #####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_table_1.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985104e-269c-47ec-a3d7-9c15042ddb19",
   "metadata": {},
   "source": [
    "Hopefuly that went without a hitch! If not give me (Sam) a shout... \n",
    "\n",
    "If you quickly take a look over at GCP and give your tab a quick refresh, you should notice that your test dataset now contains a copy of `test_table_1` and the table has a shiny new `fdm_start_date` column. You'll also notice the parser has taken a string with text and digits and has converted it into a SQL datetime - this should hopefully save a lot of manual faff in the long run!\n",
    "\n",
    "This was a pretty simple example that didn't ask much of the FDMBuilder - the second example throws a couple more curveballs into the mix, but hopefully the build script should still guide you through. When you're ready, run the below code cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a751804c-d382-4368-8586-11e2fbc483ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ##### BUILDING FDM TABLE COMPONENTS FOR test_table_2 #####\n",
      "________________________________________________________________________________\n",
      "\n",
      "1. Copying test_table_2 to CY_SAM_TEST:\n",
      "\n",
      "    Table test_table_2 copied to CY_SAM_TEST!\n",
      "\n",
      "2. Adding person_id column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    No identifier columns found! FDM process requires a person_id column \n",
      "    in each table -  or  a digest/EDRN column to be able to link  person_ids.\n",
      "    person_id/digest/EDRN columns may be present under a different name - do any \n",
      "    of the following colums contain digests or EDRNs? \n",
      "    (Note: identifiers are case sensitive)\n",
      "    \n",
      "    \n",
      "\t\tdigest_with_wrong_name\n",
      "\t\tstart_month\n",
      "\t\tstart_year\n",
      "\t\tend_month\n",
      "\t\tend_year\n",
      "    \n",
      "    If so, type the column in question. If not, type n.\n",
      "    > Response:  digest_with_wrong_name\n",
      "\n",
      "    Does digest_with_wrong_name contain person_ids, digests or EDRNs?\n",
      "    > Type either person_id, digest or EDRN:  dige\n",
      "\n",
      "    Response needs to match one of person_id, digest or EDRN and is \n",
      "    case-sensitive.\n",
      "    > Response:\n",
      "                     digest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRenaming Columns:\n",
      "\tdigest_with_wrong_name -> digest\n",
      "\tRenaming Complete\n",
      "\n",
      "\n",
      "    person_id column added\n",
      "\n",
      "3. Adding fdm_start_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event start date is required to build the observation_period table. This \n",
      "    information should be contained within one or more columns of your table. \n",
      "    If unsure a quick look at the table data in BigQuery should clarify.\n",
      "    \n",
      "    To start, is the event start data found in one column that can be easily \n",
      "    parsed with a day, month and year?\n",
      "    > Type y or n  n\n",
      "\n",
      "    We'll build the event start date beginning with the year. Where can the\n",
      "    year information be found?\n",
      "    Your response can be the name of a column that contains the year (year only,\n",
      "    other formats can't be parsed) or a static value (e.g. 2022).\n",
      "    If the year information isn't contained in one column, type quit as your \n",
      "    response, add a column with the year information and then re-run .build(). \n",
      "    You may find the .add_column() method useful for this.\n",
      "    > Response:  start_year\n",
      "\n",
      "    And now we'll move onto the month. The same guidance as above applies.\n",
      "    Remebmer, a static value like 02, or Feb, or February is acceptable.\n",
      "    Where can the event start month be found?\n",
      "    > Response:   start_month\n",
      "\n",
      "    And then day. Again a static day like 15 is fine.\n",
      "    \n",
      "    Where can the event start day be found?\n",
      "    > Response:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    adding fdm_start_date_column...\n",
      "    fdm_start_date column added\n",
      "\n",
      "4. Adding fdm_end_date column:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "    An event end date may or may not be relevant to this source data. For example, \n",
      "    hospital visits or academic school years have an end date as well as a start \n",
      "    date.\n",
      "    If you're unsure weather or not the source data should include an event end \n",
      "    date, seek help from the CYP data team.\"\n",
      "    Does this data have an event end date?\"\n",
      "    > Type y or n:  y\n",
      "\n",
      "    The process will now proceed in exactly the same way as with the event start \n",
      "    date. Refer to the guidance above if at all unsure about the responses to any\n",
      "    of the following questions.\n",
      "    Is the event end data found in one column that can be easily parsed with a \n",
      "    day, month and year?\n",
      "    > Type y or n:  n\n",
      "\n",
      "    Where can the event end year be found?\n",
      "    > Response:  end_year\n",
      "\n",
      "    Where can the event end month be found?\n",
      "    > Response:  end_month\n",
      "\n",
      "    Where can the event end day be found?\n",
      "    > Response:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fdm_end_date column added\n",
      "________________________________________________________________________________\n",
      "\n",
      "\t ##### BUILD PROCESS FOR test_table_2 COMPLETE! #####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_table_2 = FDMTable(\n",
    "    source_table_id=\"CY_FDM_BUILDER_TESTS.test_table_2\",\n",
    "    dataset_id=DATASET_ID\n",
    ")\n",
    "    \n",
    "test_table_2.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f496981-9233-45b1-aa09-815bc16e795b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Hopefully you made it through that without too much issue. Like before, if you hop over to GCP and refresh your SQL workspace, you should see a `test_table_2` in your dataset. This time the FDMTable tool has done a little more work - it renamed the (somewhat meta) `digest_with_wrong_name` column, added `person_id`s from the digest column, and has parsed the `event_start_date`s and `event_end_date`s. \n",
    "\n",
    "That's the basics of the table prep stage done. Now we can move on to actually building the FDM Dataset.\n",
    "\n",
    "## FDMDataset\n",
    "\n",
    "You'll probably note that, thus far, the FDMTable tool doesn't seem to have done anything all that dramatic. It's just copied a couple of tables into our FDM dataset, made sure the person_id is in good order and added a couple of dates. But, it's important that these boxes are ticked off properly before we try to build the rest of the FDM dataset - the `person` and `obesrvation_period` tables, and removing any problematic entries in our source data. \n",
    "\n",
    "The job of building the FDM dataset is given to the, aptly named, `FDMDataset` class. It works in a very similar way to the `FDMTable` class - you initialise it with some simple details, and then run a `.build()` method to have it work it's magic. Unlike the `FDMTable` however, the `FDMDatatset` can work said magic without the need for any user input. All that's required is:\n",
    "\n",
    "1. A dataset for your FDM\n",
    "2. Source tables that have already been build using the `FDMTable` class/tool\n",
    "3. No other tables that arent FDM source tables in the dataset (or tables that the `FDMDataset` class has built itself - but more on that later)\n",
    "\n",
    "But, if any of these requirements aren't in order, the `FDMDataset` build process will get upset and tell you about it.\n",
    "\n",
    "The dataset you've built for this tutorial *should* tick all those boxes - provided you haven't deviated off the path this notebook has been walking. If so, you're ready to build your dataset. First, initialise your `FDMDataset` instance by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a59b8a-648d-4d8d-a216-12b7b04fe6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FDMDataset(\n",
    "    dataset_id=DATASET_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c636993-fe7e-46d3-873f-e05c33f87b1e",
   "metadata": {},
   "source": [
    "and then, as with the `FDMTable`, you just run the `.build()` method, and it takes care of the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee25d00-f8e0-4849-966f-da9a9e444525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t ##### BUILDING FDM DATASET CY_SAM_TEST #####\n",
      "________________________________________________________________________________\n",
      "\n",
      "1. Checking dataset for source tables:\n",
      "\n",
      "    * test_table_1 contains:  - person_id - fdm_event_start_date \n",
      "\t-> Table ready\n",
      "    * test_table_2 contains:  - person_id - fdm_event_start_date  * fdm_event_end_date\n",
      "\t-> Table ready\n",
      "\n",
      "2. Building person table\n",
      "\n",
      "    * Person table built with 186 entries\n",
      "\n",
      "3. Separating out problem entries from source tables\n",
      "\n",
      "    test_table_1:\n",
      "\t* 45 problem entries identified and removed to test_table_1_problems\n",
      "\t* 55 entries remain in test_table_1\n",
      "    test_table_2:\n",
      "\t* 37 problem entries identified and removed to test_table_2_problems\n",
      "\t* 63 entries remain in test_table_2\n",
      "\n",
      "4. Rebuilding person table\n",
      "\n",
      "    * Person table built with 118 entries\n",
      "\n",
      "5. Building observation_period table\n",
      "\n",
      "    * observation_period table built with 118 entries\n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "\t ##### BUILD PROCESS FOR CY_SAM_TEST COMPLETE! #####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e55440-899f-47fa-a7ac-af48b54648db",
   "metadata": {},
   "source": [
    "And there you have it - your FDM. Magic.\n",
    "\n",
    "If you head over to your GCP SQL workspace, you should see some new tables that form you FDM: a `person` table, an `observation_period` table and 2 \"problem\" tables that correspond with each of the source tables. \n",
    "\n",
    "The problem tables contain the entries that have been removed for one of several possible issues or errors. If you take a look at the contents of one of these problem tables, you'll find the logic behind them pretty self explanatory - both tables contain a \"problem\" column that contains a description of the reason they were removed from the source data, for example:\n",
    "\n",
    "    \"event_start_date is after death_datetime (+42 days)\"\n",
    "    \n",
    "    \"event_start_date is before person birth_datetime - Note: Within pre-natal period\"\n",
    "    \n",
    "Note: the \"pre-natal period\" message signifies that the event starts within the 9 (or so) months or so of the mother's pregnancy - worth paying attention to for certain datasets e.g. maternity care/social care and so on - there are ways to have the `.build()` process include these entries, discussed further down.\n",
    "\n",
    "That about does it for the basics. There are a few extra helpers and functions that might be interesting once you're comfortable with the pipeline and the python environment, detailed below:\n",
    "\n",
    "## BigQuery Cell Magics\n",
    "\n",
    "The first tool isn't anything the FDM pipeline can take credit for. Packaged in the python bigquery library is a \"cell magic\", that allows you to run pure SQL queries directly from a Jupyter notebook cell. A cell magic is a little bit of syntax that adds some extra functionality to a notebook cell - the general syntax of a cell magic is `%%name-here`, so the bigquery cell magic is `%%bigquery`. Add that to the top of a cell, write your SQL below, and juypter/python will do the rest. Give the below a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e841e84e-c3c5-496b-88e5-fb50d11975a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 2/2 [00:00<00:00, 575.07query/s]                         \n",
      "Downloading: 100%|██████████| 10/10 [00:00<00:00, 10.29rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>death_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>person_source_value</th>\n",
       "      <th>gender_source_value</th>\n",
       "      <th>gender_source_concept_id</th>\n",
       "      <th>race_source_value</th>\n",
       "      <th>race_source_concept_id</th>\n",
       "      <th>ethnicity_source_value</th>\n",
       "      <th>ethnicity_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10871865</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10871865</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10877333</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10877333</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10861223</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10861223</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10855850</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10855850</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10874629</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10874629</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10855432</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10855432</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10861024</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10861024</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10874854</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10874854</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10869527</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10869527</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10856693</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10856693</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  gender_concept_id  year_of_birth  month_of_birth  day_of_birth  \\\n",
       "0   10871865           45454912           2016               1            15   \n",
       "1   10877333           45454912           2016               1            15   \n",
       "2   10861223           45454912           2010               1            15   \n",
       "3   10855850           45454912           2016               1            15   \n",
       "4   10874629           45454912           2010               1            15   \n",
       "5   10855432           45454912           2016               1            15   \n",
       "6   10861024           45454912           2016               1            15   \n",
       "7   10874854           45454912           2010               1            15   \n",
       "8   10869527           45454912           2016               2            15   \n",
       "9   10856693           45454912           2010               2            15   \n",
       "\n",
       "  birth_datetime death_datetime  race_concept_id  ethnicity_concept_id  \\\n",
       "0     2016-01-15            NaT                0                     0   \n",
       "1     2016-01-15            NaT                0                     0   \n",
       "2     2010-01-15            NaT                0                     0   \n",
       "3     2016-01-15            NaT                0                     0   \n",
       "4     2010-01-15            NaT                0                     0   \n",
       "5     2016-01-15            NaT                0                     0   \n",
       "6     2016-01-15            NaT                0                     0   \n",
       "7     2010-01-15            NaT                0                     0   \n",
       "8     2016-02-15            NaT                0                     0   \n",
       "9     2010-02-15            NaT                0                     0   \n",
       "\n",
       "   location_id  provider_id  care_site_id person_source_value  \\\n",
       "0          NaN          NaN           NaN            10871865   \n",
       "1          NaN          NaN           NaN            10877333   \n",
       "2          NaN          NaN           NaN            10861223   \n",
       "3          NaN          NaN           NaN            10855850   \n",
       "4          NaN          NaN           NaN            10874629   \n",
       "5          NaN          NaN           NaN            10855432   \n",
       "6          NaN          NaN           NaN            10861024   \n",
       "7          NaN          NaN           NaN            10874854   \n",
       "8          NaN          NaN           NaN            10869527   \n",
       "9          NaN          NaN           NaN            10856693   \n",
       "\n",
       "  gender_source_value  gender_source_concept_id race_source_value  \\\n",
       "0                Male                  45454912           British   \n",
       "1              Female                  45454912           British   \n",
       "2              Female                  45454912           British   \n",
       "3              Female                  45454912           British   \n",
       "4                Male                  45454912           British   \n",
       "5              Female                  45454912           British   \n",
       "6                Male                  45454912           British   \n",
       "7              Female                  45454912           British   \n",
       "8              Female                  45454912           British   \n",
       "9              Female                  45454912           British   \n",
       "\n",
       "   race_source_concept_id ethnicity_source_value  ethnicity_source_concept_id  \n",
       "0                       0                   NULL                            0  \n",
       "1                       0                   NULL                            0  \n",
       "2                       0                   NULL                            0  \n",
       "3                       0                   NULL                            0  \n",
       "4                       0                   NULL                            0  \n",
       "5                       0                   NULL                            0  \n",
       "6                       0                   NULL                            0  \n",
       "7                       0                   NULL                            0  \n",
       "8                       0                   NULL                            0  \n",
       "9                       0                   NULL                            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM `CY_FDM_MASTER.person`\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3cd18-2f5c-4827-a776-006d8e524b71",
   "metadata": {},
   "source": [
    "Easy. \n",
    "\n",
    "For those familiar with the pandas library, you can store the results of your query as a `DataFrame` by naming it immediately after the `%%bigquery` magic. So the following cell runs the same query as above, and stores the result in `eg_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683f9318-6bda-4ca0-9e1d-c587542e2c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 492.35query/s] \n",
      "Downloading: 100%|██████████| 10/10 [00:00<00:00, 10.20rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery eg_df\n",
    "SELECT *\n",
    "FROM `CY_FDM_MASTER.person`\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb533bd-b422-4d39-99ef-a76bb942d9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>death_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>person_source_value</th>\n",
       "      <th>gender_source_value</th>\n",
       "      <th>gender_source_concept_id</th>\n",
       "      <th>race_source_value</th>\n",
       "      <th>race_source_concept_id</th>\n",
       "      <th>ethnicity_source_value</th>\n",
       "      <th>ethnicity_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10871865</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10871865</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10877333</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10877333</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10861223</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10861223</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10855850</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10855850</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10874629</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10874629</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10855432</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10855432</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10861024</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10861024</td>\n",
       "      <td>Male</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10874854</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10874854</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10869527</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10869527</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10856693</td>\n",
       "      <td>45454912</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10856693</td>\n",
       "      <td>Female</td>\n",
       "      <td>45454912</td>\n",
       "      <td>British</td>\n",
       "      <td>0</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  gender_concept_id  year_of_birth  month_of_birth  day_of_birth  \\\n",
       "0   10871865           45454912           2016               1            15   \n",
       "1   10877333           45454912           2016               1            15   \n",
       "2   10861223           45454912           2010               1            15   \n",
       "3   10855850           45454912           2016               1            15   \n",
       "4   10874629           45454912           2010               1            15   \n",
       "5   10855432           45454912           2016               1            15   \n",
       "6   10861024           45454912           2016               1            15   \n",
       "7   10874854           45454912           2010               1            15   \n",
       "8   10869527           45454912           2016               2            15   \n",
       "9   10856693           45454912           2010               2            15   \n",
       "\n",
       "  birth_datetime death_datetime  race_concept_id  ethnicity_concept_id  \\\n",
       "0     2016-01-15            NaT                0                     0   \n",
       "1     2016-01-15            NaT                0                     0   \n",
       "2     2010-01-15            NaT                0                     0   \n",
       "3     2016-01-15            NaT                0                     0   \n",
       "4     2010-01-15            NaT                0                     0   \n",
       "5     2016-01-15            NaT                0                     0   \n",
       "6     2016-01-15            NaT                0                     0   \n",
       "7     2010-01-15            NaT                0                     0   \n",
       "8     2016-02-15            NaT                0                     0   \n",
       "9     2010-02-15            NaT                0                     0   \n",
       "\n",
       "   location_id  provider_id  care_site_id person_source_value  \\\n",
       "0          NaN          NaN           NaN            10871865   \n",
       "1          NaN          NaN           NaN            10877333   \n",
       "2          NaN          NaN           NaN            10861223   \n",
       "3          NaN          NaN           NaN            10855850   \n",
       "4          NaN          NaN           NaN            10874629   \n",
       "5          NaN          NaN           NaN            10855432   \n",
       "6          NaN          NaN           NaN            10861024   \n",
       "7          NaN          NaN           NaN            10874854   \n",
       "8          NaN          NaN           NaN            10869527   \n",
       "9          NaN          NaN           NaN            10856693   \n",
       "\n",
       "  gender_source_value  gender_source_concept_id race_source_value  \\\n",
       "0                Male                  45454912           British   \n",
       "1              Female                  45454912           British   \n",
       "2              Female                  45454912           British   \n",
       "3              Female                  45454912           British   \n",
       "4                Male                  45454912           British   \n",
       "5              Female                  45454912           British   \n",
       "6                Male                  45454912           British   \n",
       "7              Female                  45454912           British   \n",
       "8              Female                  45454912           British   \n",
       "9              Female                  45454912           British   \n",
       "\n",
       "   race_source_concept_id ethnicity_source_value  ethnicity_source_concept_id  \n",
       "0                       0                   NULL                            0  \n",
       "1                       0                   NULL                            0  \n",
       "2                       0                   NULL                            0  \n",
       "3                       0                   NULL                            0  \n",
       "4                       0                   NULL                            0  \n",
       "5                       0                   NULL                            0  \n",
       "6                       0                   NULL                            0  \n",
       "7                       0                   NULL                            0  \n",
       "8                       0                   NULL                            0  \n",
       "9                       0                   NULL                            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da048a-a525-40ff-83e5-61ab29d50f65",
   "metadata": {},
   "source": [
    "If so inclined, you can run and document your SQL pipelines in a notebook by using the above cell magics, and then documenting your work in markdown text cells (like this). \n",
    "\n",
    "Now on to the extra bits of the FDM pipeline. \n",
    "\n",
    "## FDMTable Helpers\n",
    "\n",
    "### copy_table_to_dataset\n",
    "\n",
    "You may have noticed the first stage of the table `.build()` process copying the source table into the FDM dataset. This doesn't happen automatically and, when you initialise a new `FDMTable`, you'll need to add a copy to the new FDM dataset before you can use any of the below helper functions. It's quickly done by running:\n",
    "\n",
    "### add_column\n",
    "\n",
    "### drop_column\n",
    "\n",
    "### rename_columns\n",
    "\n",
    "### head\n",
    "\n",
    "### quick_build\n",
    "\n",
    "## FDMDataset Helpers\n",
    "\n",
    "### create_dataset\n",
    "\n",
    "## Other Helpers\n",
    "\n",
    "not attached to the table/dataset objects\n",
    "\n",
    "### check_dataset_exists / check_table_exists\n",
    "\n",
    "### clear_dataset\n",
    "\n",
    "## Example Workflow\n",
    "\n",
    "Some examples of using helper functions more fluidly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80f9332f-623a-46ea-b44b-7da015044118",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table_3.copy_table_to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1136a3-a7bc-4680-95dc-cbfbc1062a61",
   "metadata": {},
   "source": [
    "The above didn't actually do anything, as the test_table_1 already exists in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb33c24-8d18-4905-80aa-76a7dad8e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = CLIENT.get_table(\"CY_FDM_MASTER.person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b73373-aca0-4fe3-98c0-3044c812ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_id\n",
      "INTEGER\n",
      "gender_concept_id\n",
      "INTEGER\n",
      "year_of_birth\n",
      "INTEGER\n",
      "month_of_birth\n",
      "INTEGER\n",
      "day_of_birth\n",
      "INTEGER\n",
      "birth_datetime\n",
      "DATETIME\n",
      "death_datetime\n",
      "DATETIME\n",
      "race_concept_id\n",
      "INTEGER\n",
      "ethnicity_concept_id\n",
      "INTEGER\n",
      "location_id\n",
      "INTEGER\n",
      "provider_id\n",
      "INTEGER\n",
      "care_site_id\n",
      "INTEGER\n",
      "person_source_value\n",
      "STRING\n",
      "gender_source_value\n",
      "STRING\n",
      "gender_source_concept_id\n",
      "INTEGER\n",
      "race_source_value\n",
      "STRING\n",
      "race_source_concept_id\n",
      "INTEGER\n",
      "ethnicity_source_value\n",
      "STRING\n",
      "ethnicity_source_concept_id\n",
      "INTEGER\n"
     ]
    }
   ],
   "source": [
    "for field in blah.schema:\n",
    "    print(field.name)\n",
    "    print(field.field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ab6268c-79a8-4e06-a5be-0f8b6689ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 1132.88query/s]                        \n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.13rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery blah\n",
    "SELECT ARRAY_AGG(DISTINCT gender_source_concept_id) AS result\n",
    "FROM `yhcr-prd-phm-bia-core.CY_FDM_MASTER.person`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b99b113-86ad-486e-982d-9aa84c7b4b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 3/3 [00:00<00:00, 707.74query/s]                         \n",
      "Downloading: 100%|██████████| 1/1 [00:01<00:00,  1.07s/rows]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery blah\n",
    "SELECT COUNT(DISTINCT race_concept_id) AS n\n",
    "FROM `yhcr-prd-phm-bia-core.CY_FDM_MASTER.person`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "947d9850-3ae0-4021-8f3c-3c82f5afbaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n\n",
       "0  33"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd4b94-1eb6-486d-80d5-78519bccaa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8024e41-ade6-47b7-b9d4-99ef1d4baa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31776a91-4080-4583-b737-c26bd07e03ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
